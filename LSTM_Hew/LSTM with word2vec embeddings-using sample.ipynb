{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LSTM with word2vec embeddings - using sample</h1><br>\n",
    "https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#instructions here:\n",
    "https://stackoverflow.com/questions/17323336/automatically-play-sound-in-ipython-notebook<br>\n",
    "#sound downloaded to server from here: https://www.soundjay.com/beep-sounds-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = 'beep.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"beep.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I tried to get this working with a function but it this had to be the solution:\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart = time.time()\\nprint(\"hello\")\\nend = time.time()\\ntime_taken = str(round((end - start) * 1000000,1))\\nprint(time_taken + \" seconds\") \\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "time_taken = str(round((end - start) * 1000000,1))\n",
    "print(time_taken + \" seconds\") \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9 seconds\n",
      "0.1 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Single model may achieve LB scores at around 0.29+ ~ 0.30+\n",
    "Average ensembles can easily get 0.28+ or less\n",
    "Don't need to be an expert of feature engineering\n",
    "All you need is a GPU!!!!!!!\n",
    "\n",
    "The code is tested on Keras 2.0.0 using Tensorflow backend, and Python 2.7\n",
    "\n",
    "According to experiments by kagglers, Theano backend with GPU may give bad LB scores while\n",
    "        the val_loss seems to be fine, so try Tensorflow backend first please\n",
    "'''\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#original\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')\n",
    "\n",
    "#issues with stdout. Using solution below from https://stackoverflow.com/questions/25494182/print-not-showing-in-ipython-notebook-python\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/ 60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ended---\n",
      "lstm_261_109_0.16_0.26\n",
      "0.0 seconds\n",
      "0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## set directories and parameters\n",
    "########################################\n",
    "start = time.time()\n",
    "\n",
    "BASE_DIR = 'input_sample/'\n",
    "WORD2VEC_DIR = 'input/'\n",
    "EMBEDDING_FILE = WORD2VEC_DIR + 'GoogleNews-vectors-negative300.bin'\n",
    "                            #GoogleNews-vectors-negative300.bin\n",
    "TRAIN_DATA_FILE = BASE_DIR + 'train.csv'\n",
    "TEST_DATA_FILE = BASE_DIR + 'test.csv'\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "num_lstm = np.random.randint(175, 275)\n",
    "num_dense = np.random.randint(100, 150)\n",
    "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
    "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
    "\n",
    "act = 'relu'\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set\n",
    "\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
    "        rate_drop_dense)\n",
    "print(\"---ended---\")\n",
    "print(STAMP)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/ 60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Going to copy it verbatim and see how it runs. But copying it in chunks to manage errors better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors\n",
      "51.9 seconds\n",
      "0.9 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"beep.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "## index word vectors\n",
    "########################################\n",
    "start = time.time()\n",
    "\n",
    "print('Indexing word vectors')\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, \\\n",
    "        binary=True)\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/ 60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors of word2vec\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result:\n",
    "Found 3000000 word vectors of word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "0.0 seconds\n",
      "0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## process texts in datasets\n",
    "########################################\n",
    "print('Processing text dataset')\n",
    "\n",
    "# The function \"text_to_wordlist\" is from\n",
    "# https://www.kaggle.com/currie32/quora-question-pairs/the-importance-of-cleaning-text\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/ 60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c497421492a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtexts_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_wordlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "texts_1 = [] \n",
    "texts_2 = []\n",
    "labels = []\n",
    "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        texts_1.append(text_to_wordlist(values[3]))\n",
    "        texts_2.append(text_to_wordlist(values[4]))\n",
    "        labels.append(int(values[5]))\n",
    "print('Found %s texts in train.csv' % len(texts_1))\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/ 60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 texts in test.csv\n",
      "0.0 seconds\n",
      "0.0 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"beep.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "test_texts_1 = []\n",
    "test_texts_2 = []\n",
    "test_ids = []\n",
    "with codecs.open(TEST_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        test_texts_1.append(text_to_wordlist(values[1]))\n",
    "        test_texts_2.append(text_to_wordlist(values[2]))\n",
    "        test_ids.append(values[0])\n",
    "print('Found %s texts in test.csv' % len(test_texts_1))\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_1 + texts_2 + test_texts_1 + test_texts_2)\n",
    "\n",
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
    "test_sequences_2 = tokenizer.texts_to_sequences(test_texts_2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(labels)\n",
    "print('Shape of data tensor:', data_1.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## prepare embeddings\n",
    "########################################\n",
    "print('Preparing embedding matrix')\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## sample train/validation data\n",
    "########################################\n",
    "#np.random.seed(1234)\n",
    "perm = np.random.permutation(len(data_1))\n",
    "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "data_1_train = np.vstack((data_1[idx_train], data_2[idx_train]))\n",
    "data_2_train = np.vstack((data_2[idx_train], data_1[idx_train]))\n",
    "labels_train = np.concatenate((labels[idx_train], labels[idx_train]))\n",
    "\n",
    "data_1_val = np.vstack((data_1[idx_val], data_2[idx_val]))\n",
    "data_2_val = np.vstack((data_2[idx_val], data_1[idx_val]))\n",
    "labels_val = np.concatenate((labels[idx_val], labels[idx_val]))\n",
    "\n",
    "weight_val = np.ones(len(labels_val))\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[labels_val==0] = 1.309028344\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## define the model structure\n",
    "########################################\n",
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False)\n",
    "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
    "\n",
    "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "merged = concatenate([x1, y1])\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "merged = Dense(num_dense, activation=act)(merged)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## add class weight\n",
    "########################################\n",
    "if re_weight:\n",
    "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "else:\n",
    "    class_weight = None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "model = Model(inputs=[sequence_1_input, sequence_2_input], \\\n",
    "        outputs=preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['acc'])\n",
    "#model.summary()\n",
    "print(STAMP)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "bst_model_path = STAMP + '.h5'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "#Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "hist = model.fit([data_1_train, data_2_train], labels_train, \\\n",
    "        validation_data=([data_1_val, data_2_val], labels_val, weight_val), \\\n",
    "        epochs=200, batch_size=2048, shuffle=True, \\\n",
    "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.load_weights(bst_model_path)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "bst_val_score = min(hist.history['val_loss'])\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "########################################\n",
    "## make the submission\n",
    "########################################\n",
    "print('Start making the submission before fine-tuning')\n",
    "\n",
    "preds = model.predict([test_data_1, test_data_2], batch_size=8192, verbose=1)\n",
    "preds += model.predict([test_data_2, test_data_1], batch_size=8192, verbose=1)\n",
    "preds /= 2\n",
    "\n",
    "submission = pd.DataFrame({'test_id':test_ids, 'is_duplicate':preds.ravel()})\n",
    "submission.to_csv('%.4f_'%(bst_val_score)+STAMP+'.csv', index=False)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "time_taken_seconds = str(round((end - start),1))\n",
    "time_taken_minutes = str(round((end - start)/60,1))\n",
    "print(time_taken_seconds + \" seconds\")\n",
    "print(time_taken_minutes + \" minutes\")\n",
    "#alert to when kernel stops\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
